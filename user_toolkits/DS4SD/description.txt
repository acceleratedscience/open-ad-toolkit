the below is a description of the DeepSearch toolkit capabilities that is implemented through statements in the Adccl client

Deep Search uses natural language processing to ingest and analyze massive amounts of data—structured and unstructured. Researchers can then extract, explore, and make connections faster than ever.
Solutions that once took months to find are now being discovered in a matter of days.
See how we used Deep Search to discover a new molecule
How it works
Deep Search imports and analyzes data from public, private, structured, and unstructured sources. AI then breaks down the data and classifies it into fundamental parts.
The Deep Search process starts with unstructured data such as journal articles, patents, or technical reports. No matter whether this data comes from public or proprietary sources, businesses can leverage both securely through our hybrid cloud.
After reviewing unstructured data, the user annotates a few documents to create an AI model. The model then classifies all documents into their fundamental parts. By using this AI model and NLP (Natural Language Processing), Deep Search is able to ingest and understand large collections of documents and unstructured data at scale, automatically extracting semantic units and their relationships.
Once the data has been consolidated and extracted, Deep Search organizes and structures it into a searchable knowledge graph—enabling users to robustly explore information extracted from tens of thousands of documents without having to read a single paper.






